{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pluralsite ML Coding Challenge\n",
    "Daniel Stack, dstack1776@gmail.com \n",
    "\n",
    "github handle: dstack1776\n",
    "\n",
    "June 23, 2018\n",
    "\n",
    "# Instructions\n",
    "\n",
    "There are two separate Python files. They should be put in the same directory. The first of these is \"Pluralsight Class Modules\". I have provided it both as a Jupyter Notebook and as a standard Python file. The function main makes a number of calls to parse the csv files, calculate similarity, and create an sqlite database \"dstack.db\" that stores the results in the table distance_matrix, with three columns - src_usr, dst_usr, and distance. This takes several minutes to complete - there's some optimizations I'd consider (and will discuss below) were this not a model but rather a much larger dataset.\n",
    "\n",
    "The second file is rest_dstack.py that serves as a RESTful API interface. Like the first program, it is a toy with basic functionality. In this case is is listening to 127.0.0.1:5002. There are two get commands, users and usersn, detailed below.\n",
    "\n",
    "## users\n",
    "\"users\" has a single argument, the user handle, which ranges from 1 to 10000, inclusive. It returns a dictionary of the ten nearest user handles (not including itself) and the distance, which ranges from 0 (identical) to 1 (nothing in common). For example, 127.0.0.1:5002/users/9999 will return the ten nearest handles to user handle 9999 as well as the distances from 9999. I ran this program straight out of IDLE. It needs to be run after \"Pluralsight Class Modules\" as it does a simple sql select from dstack.db.\n",
    "\n",
    "Example output for 127.0.0.1:5002/users/9999\n",
    "\n",
    "```python\n",
    "{\"1562\": 0.0, \"5238\": 0.0, \"6303\": 0.0, \"4484\": 0.5, \"4432\": 0.5196152422706632, \"906\": 0.5204164998665332, \"2200\": 0.5443310539518175, \"3605\": 0.5446711546122731, \"5071\": 0.5608545472127794, \"453\": 0.5773502691896258}\n",
    "```\n",
    "\n",
    "## usersn\n",
    "\"usersn\" has two arguments, id and num. id is used for the user handle while num indicates how many handles should be returned, in ascending order, starting with the closest.\n",
    "\n",
    "Example output for http://127.0.0.1:5002/usersn?id=9999&num=15\n",
    "```python\n",
    "{\"1562\": 0.0, \"5238\": 0.0, \"6303\": 0.0, \"4484\": 0.5, \"4432\": 0.5196152422706632, \"906\": 0.5204164998665332, \"2200\": 0.5443310539518175, \"3605\": 0.5446711546122731, \"5071\": 0.5608545472127794, \"453\": 0.5773502691896258, \"637\": 0.5773502691896258, \"2754\": 0.5773502691896258, \"5411\": 0.5773502691896258, \"6188\": 0.5773502691896258, \"7688\": 0.5773502691896258}\n",
    "```\n",
    "\n",
    "\n",
    "# Similarity Calculation\n",
    "## Aborted Effort\n",
    "When I first looked into this problem, I had initially considered using cosine similarity for the User Assessments. With all of the assessments having numeric values it seemed a reasonable mechanism. However, this entailed creating a column for every assessment type and the code to an **extremely** long time to run, even with this limited dataset. Moreover, it became clear that even were the performance model to be overcome, it was not a good model. There were users who took no assessments - which made them identical to other users who took no assessments, as I needed to give them some numeric value. In the end, this did not appear a good model to use.\n",
    "\n",
    "## Three-Axis Jaccard Distance\n",
    "Instead, I made use of three axes of Jaccard distance. I set up an axis for assessments, classes examined, and self-described interests.\n",
    "\n",
    "Jaccard similarity is used to compare sets. It is the cardinality of the intersection of two sets divided by the union of the two sets. I added some code to make the similarity between empty sets as 0 (so as to avoid divide by zero error). Given the most similar (identical) would have a 1 under this model, I subtracted the result from 1 to get a distance.\n",
    "\n",
    "I settled on making use of a set compare given the wide variety of interests, courses, and assessments. This avoided hoops I ran into when attempting to make use of cosine similarity.\n",
    "\n",
    "### Assessments\n",
    "One thing I did not want to lose on assessments were the scores. I wanted similarity between people who took assessments in a given are but I wanted even greater similarity if their level of experience were similar. To do this I added three possible tags to every assessment - Novice, Proficient, and Expert. Someone who tested as a Novice in Python, for example, would have the entry 'Python-Novice' added to their assessment set. Someone who tested as an Expert in Python have 'Python-Novice', 'Python-Proficient', and 'Python-Expert; added to their assessment set. In this model, two Python Experts would have a strong level of similarity given they would have three matching entries in their sets. Similarly a Python Novice and Python Expert would still have some level of similarity. I used benchmarks of 100 and 200 to show Proficiency and Expertise, aligning with Pluralsight's testing algorithms.\n",
    "\n",
    "### Interests\n",
    "Interests were the most straightforward as they were simple binaries - a user was either interested in something or not. I added interests into a user's Interest set.\n",
    "\n",
    "### Classes\n",
    "Given the variety of courses, I took advantage of the course tags to simplify areas of interest into broader categories - for each user, instead of using the course name I instead mapped in the tags from the separate csv file, using logic akin to a SQL left join. Like the Assessments, I took advantage of the difficulty of the course. I did not use the time spent on a class's webpage, an area of potential enhancement - perhaps using it to measure an intensity of interest - or to possibly discard entries that a user spent an extremely brief amount of time on.\n",
    "\n",
    "## Combining the Three Axes\n",
    "Since I calculated three separate distance axes, I combined them using a simple application of the Pythagorean Theorem, and to keep the result scaled from 0 to 1, I divided this result by the square root of 3. \n",
    "\n",
    "\n",
    "# Considerations at Larger Scale\n",
    "\n",
    "I was able to take advantage of storing a lot of data in memory. Indeed, some of my initial efforts involved building a Jaccard Distance table for everything. It would have been possible to go with this model and not used a database table at all. However, the database table has as an advantage it can be built over time and in pieces. For example, I built the SQL table for one user at a time, comparing it with all potential other users in one 1D array. This was a large data structure - at a larger scale it might be reasonable (or even necessary) to build it in smaller chunks. Conversely, I performed and committed the SQL writes one at a time - by use of transactions - http://bytes.schibsted.com/speeding-up-sqlite-insert-operations/ - it becomes possible to speed up that process. \n",
    "\n",
    "To speed up calculations it is possible to take advantage of the distance between a source and destination is commutative - you only need to calculate it once.\n",
    "\n",
    "# Other Thoughts\n",
    "\n",
    "One thing I would have liked would have been some information as to what sorts of assessments, class tags, and interests are similar to one another. Domain knowledge could have been used to make such decisions, likely codifying it with a CSV file similar to the classes' tag file.  For example, Pluralsight's webpage breaks the assessments into Development, IT Ops, Data, Security, Creative. These may have been data points appropriate for similarity calculations.\n",
    "\n",
    "The REST interface is fairly basic and a good opportunity for improvement. This was my first exercise at creating a REST interface - since on my interview with Connor I spoke how I have talent at developing new skills, it seemed an absolutely fair challenge for me to illustrate my capacity to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import array\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('dstack.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distances_array(in_array, num_users):\n",
    "    \"\"\"\n",
    "    Create an array of Jaccard distances for N users by N users - in the sample set this would\n",
    "    be 10,000 by 10,000. In the end I did not use this method for my final design but am\n",
    "    maintaining it for the time being.\n",
    "    \n",
    "    Inputs - \n",
    "    in_array - a 1D array w/ an entry per user. The entry is a set for Jaccard distance calcualtion.\n",
    "    num_users - Number of users\n",
    "    \n",
    "    Returns - A Jaccard distance array\n",
    "    \"\"\"\n",
    "\n",
    "    distance_sets = np.full((num_users, num_users),1.0)\n",
    "\n",
    "    for src_index, src_row in enumerate(distance_sets):\n",
    "\n",
    "        for dst_index, dst_row in enumerate(in_array):\n",
    "            # do a triangle and mirror\n",
    "            if src_index > dst_index:\n",
    "                continue\n",
    "            src_row = in_array[src_index]\n",
    "            dst_row = in_array[dst_index]\n",
    "            if src_row and dst_row:\n",
    "                # if either set is empty no point continuing. Otherwise get cardinalities\n",
    "                intersection_cardinality = len(set.intersection(*[set(src_row), set(dst_row)]))\n",
    "                union_cardinality = len(set.union(*[set(src_row), set(dst_row)]))\n",
    "                distance_sets[src_index][dst_index] = 1.0 - (\n",
    "                    float(intersection_cardinality)/float(union_cardinality))\n",
    "                \n",
    "    for src_index, src_row in enumerate(distance_sets):\n",
    "        for dst_index, dst_row in enumerate(distance_sets):\n",
    "            # mirror half of the triangle\n",
    "            if src_index > dst_index:\n",
    "                distance_sets[src_index][dst_index] = distance_sets[dst_index][src_index]\n",
    "        print(distance_sets[src_index])\n",
    "    return distance_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jaccard_distances_user(in_array, user_handle, num_users):\n",
    "    \"\"\"\n",
    "    For a given user_handle, calculate the distance to all other users. \n",
    "    In the end I did not use this method for my final design but am\n",
    "    maintaining it for the time being.\n",
    "    \n",
    "    Inputs - \n",
    "    in_array - a 1D array w/ an entry per user. The entry is a set for Jaccard distance calcualtion.\n",
    "    user_handle - 1-based user handle\n",
    "    num_users - Number of users\n",
    "    \n",
    "    Returns - A Jaccard distance array for the given user handle   \n",
    "    \"\"\"\n",
    "    \n",
    "    distance_sets = np.full((num_users),1.0) # initialize all distances to 1\n",
    "    src_index = user_handle - 1 # array is 0-based\n",
    "    \n",
    "    for dst_index, dst_row in enumerate(in_array):\n",
    "        src_row = in_array[src_index]\n",
    "        dst_row = in_array[dst_index]\n",
    "        if src_row and dst_row:\n",
    "            # if either set is empty no point continuing. Otherwise get cardinalities\n",
    "            intersection_cardinality = len(set.intersection(*[set(src_row), set(dst_row)]))\n",
    "            union_cardinality = len(set.union(*[set(src_row), set(dst_row)]))\n",
    "            distance_sets[dst_index] = 1.0 - (\n",
    "                float(intersection_cardinality)/float(union_cardinality))\n",
    "    return distance_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3_axis_distances_for_one_handle(user_handle):\n",
    "    \"\"\"\n",
    "    For a given user_handle, calculate the distance to all other users across all three axes. \n",
    "    Assumes Assessments_Obj, Interests_Obj, and Classes_Obj are global. Performs multiple \n",
    "    Jaccard Distance caluclations and then uses the Pythagorean Theorem to combine them.\n",
    "    \n",
    "    In the end I did not use this method for my final design but am\n",
    "    maintaining it for the time being.\n",
    "    \n",
    "    Inputs - \n",
    "    in_array - a 1D array w/ an entry per user. The entry is a set for Jaccard distance calcualtion.\n",
    "    user_handle - 1-based user handle\n",
    "    num_users - Number of users\n",
    "    \n",
    "    Returns - A Jaccard distance array for the given user handle   \n",
    "    \"\"\"\n",
    "    # note user-handle is 1-based\n",
    "    assessment_distance = Assessments_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    interests_distance = Interests_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    classes_distance = Classes_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    \n",
    "    overall_distance = (np.sqrt((assessment_distance ** 2) + (interests_distance ** 2) + \\\n",
    "                                (classes_distance ** 2))) / np.sqrt(3)\n",
    "    \n",
    "    return overall_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_3_axis_distances_for_one_handle(Assmnts_Obj, Ints_Obj, Cls_Obj, user_handle):\n",
    "    \"\"\"\n",
    "    For a given user_handle, calculate the distance to all other users across all three axes. \n",
    "    Assumes Assessments_Obj, Interests_Obj, and Classes_Obj are global. Performs multiple \n",
    "    Jaccard Distance caluclations and then uses the Pythagorean Theorem to combine them. \n",
    "    Write results to SQLite table.\n",
    "    \n",
    "    Inputs - \n",
    "    Assmnts_Obj - A member of the Assessments class\n",
    "    Ints_Obj - A member of the Interests class\n",
    "    Cls_Obj - A member of the Classes class\n",
    "    user_handle - 1-based user handle\n",
    "    \n",
    "    Returns - Nothing. Results written to SQLite table.   \n",
    "    \"\"\"\n",
    "\n",
    "    # note user-handle is 1-based\n",
    "    assessment_distance = Assmnts_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    interests_distance = Ints_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    classes_distance = Cls_Obj.calculate_handle_jaccard_distances(user_handle)\n",
    "    \n",
    "    overall_distance = (np.sqrt((assessment_distance ** 2) + (interests_distance ** 2) + \\\n",
    "                                (classes_distance ** 2))) / np.sqrt(3)\n",
    "    conn = sqlite3.connect('dstack.db')\n",
    "  \n",
    "    c = conn.cursor()\n",
    "    for idx, entry in enumerate(overall_distance):\n",
    "        c.execute(\"\"\"INSERT INTO distance_matrix VALUES (?, ?, ?)\"\"\", \n",
    "                  (user_handle, idx + 1, overall_distance[idx],))\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Save (commit) the changes\n",
    "    conn.commit()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PS_Data:\n",
    "    \"\"\"\n",
    "    Parent class for Assessments, Intersts, and Classes. Stores dataframe for corresponding csv\n",
    "    file as well as user_data_sets which stores sets that indicate Assessments, Intersts, and\n",
    "    Classes for all users. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_file):\n",
    "        self.input_file = input_file\n",
    "        self.data = None\n",
    "        self.user_list = None\n",
    "        self.num_users = 0\n",
    "        self.user_data_sets = None\n",
    "        self.jaccard_distances = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Read csv file into a pandas dataframe.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(self.input_file)\n",
    "\n",
    "    def get_user_handles(self):\n",
    "        \"\"\"\n",
    "        Get all the unique user handles associated with this dataframe\n",
    "        \"\"\"\n",
    "        return self.data.user_handle.unique()\n",
    "    \n",
    "    def set_users(self, user_list):\n",
    "        \"\"\"\n",
    "        Use the user_list to define all possible users, not just those associated \n",
    "        with the inheriting classes. Allows the set arrays to match in size between\n",
    "        classes.\n",
    "        \"\"\"\n",
    "        self.user_list = user_list\n",
    "        self.num_users = len(user_list)\n",
    "        \n",
    "    def calculate_all_jaccard_distances(self):\n",
    "        if self.user_data_sets is None:\n",
    "            print('calculate_all_jaccard_distances: need to user_data_sets first')\n",
    "        self.jaccard_distances = jaccard_distances_array(self.user_data_sets, self.num_users)\n",
    "        \n",
    "    def calculate_handle_jaccard_distances(self, handle):\n",
    "        if self.user_data_sets is None:\n",
    "            print('calculate_all_jaccard_distances: need to user_data_sets first')\n",
    "        return jaccard_distances_user(self.user_data_sets, handle, self.num_users)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assessments(PS_Data):\n",
    "    \"\"\"\n",
    "    Class to store assessment related information.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_file):\n",
    "        PS_Data.__init__(self, input_file)\n",
    "        \n",
    "        \n",
    "        self.load_data()\n",
    "    \n",
    "        \n",
    "    def load_user_data_set(self):\n",
    "        \"\"\"\n",
    "        Convert the dataframe into a user handle based array of sets indicating\n",
    "        assessment results.\n",
    "        \"\"\"\n",
    "        if self.num_users == 0:\n",
    "            print('load_user_data_set: Need to load user data to classes first')\n",
    "            return\n",
    "\n",
    "        assessment_set = [set() for x in range(len(user_list))]\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            curr_user = assessment_set[row.user_handle-1]\n",
    "            if (row.user_assessment_score >= 200):\n",
    "                curr_user.add(row.assessment_tag +'_Expert')\n",
    "                curr_user.add(row.assessment_tag + '_Proficient')\n",
    "                curr_user.add(row.assessment_tag +'_Novice')\n",
    "            elif (row.user_assessment_score >= 100):\n",
    "                curr_user.add(row.assessment_tag + '_Proficient')\n",
    "                curr_user.add(row.assessment_tag + '_Novice')\n",
    "            else:\n",
    "                curr_user.add(row.assessment_tag + '_Novice')\n",
    "        self.user_data_sets = assessment_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interests(PS_Data):\n",
    "    \"\"\"\n",
    "    Class to store interests related information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_file):\n",
    "        \n",
    "        PS_Data.__init__(self, input_file)\n",
    "        \n",
    "        \n",
    "        self.load_data()\n",
    "    \n",
    "    def load_user_data_set(self):\n",
    "        \"\"\"\n",
    "        Convert the dataframe into a user handle based array of sets indicating\n",
    "        interests.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.num_users == 0:\n",
    "            print('load_user_data_set: Need to load user data to classes first')\n",
    "            return\n",
    "\n",
    "        interest_set = [set() for x in range(len(user_list))]\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            curr_user = interest_set[row.user_handle-1]\n",
    "            curr_user.add(row.interest_tag)\n",
    "        self.user_data_sets = interest_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classes(PS_Data):\n",
    "    \"\"\"\n",
    "    Class to store class-interest related information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_file, tags_file):\n",
    "        PS_Data.__init__(self, input_file)\n",
    "        self.tags_file = tags_file\n",
    "        self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loading dataframe for Classes is slightly more complex as it also makes use of the \n",
    "        tags file.\n",
    "        \"\"\"\n",
    "        self.data_course_tags = pd.read_csv(self.tags_file)\n",
    "        self.data  = pd.read_csv(self.input_file)\n",
    "\n",
    "        self.data = self.data.merge(self.data_course_tags[['course_id', 'course_tags']], on=['course_id'])\n",
    "        self.data.drop('view_date', axis=1, inplace=True)\n",
    "        self.data.drop('author_handle', axis=1, inplace=True)\n",
    "        self.data.drop('view_time_seconds', axis=1, inplace=True)\n",
    "        self.data.drop('course_id', axis=1, inplace=True)\n",
    "        self.data.drop_duplicates(inplace=True)\n",
    "        \n",
    "        \n",
    "    def load_user_data_set(self):  \n",
    "        \"\"\"\n",
    "        Convert the dataframe into a user handle based array of sets indicating\n",
    "        class interests.\n",
    "        \"\"\"\n",
    "\n",
    "        course_set = [set() for x in range(len(user_list))]\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            curr_user = course_set[row.user_handle-1]\n",
    "            course_tag = str(row.course_tags)\n",
    "            course_tag = course_tag + '_' \n",
    "            curr_user.add(course_tag + row.level)\n",
    "            if row.level == 'Advanced':\n",
    "                curr_user.add(course_tag + 'Intermediate')\n",
    "                curr_user.add(course_tag + 'Beginner')\n",
    "            elif row.level == 'Intermediate':\n",
    "                curr_user.add(course_tag + 'Beginner')\n",
    "        self.user_data_sets = course_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_table():\n",
    "    \"\"\"\n",
    "    Connect to the database 'dstack.db' and create the distance_matrix table.\n",
    "    Delete the table if it already exists.\n",
    "    \n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect('dstack.db')\n",
    "\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create table\n",
    "\n",
    "    c.execute('''DROP TABLE IF EXISTS distance_matrix''')\n",
    "\n",
    "    c.execute('''CREATE TABLE distance_matrix\n",
    "             (src_usr integer, dst_usr integer, distance real)''')\n",
    "    # Save (commit) the changes\n",
    "    conn.commit()\n",
    "\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "400\n",
      "425\n",
      "450\n",
      "475\n",
      "500\n",
      "525\n",
      "550\n",
      "575\n",
      "600\n",
      "625\n",
      "650\n",
      "675\n",
      "700\n",
      "725\n",
      "750\n",
      "775\n",
      "800\n",
      "825\n",
      "850\n",
      "875\n",
      "900\n",
      "925\n",
      "950\n",
      "975\n",
      "1000\n",
      "1025\n",
      "1050\n",
      "1075\n",
      "1100\n",
      "1125\n",
      "1150\n",
      "1175\n",
      "1200\n",
      "1225\n",
      "1250\n",
      "1275\n",
      "1300\n",
      "1325\n",
      "1350\n",
      "1375\n",
      "1400\n",
      "1425\n",
      "1450\n",
      "1475\n",
      "1500\n",
      "1525\n",
      "1550\n",
      "1575\n",
      "1600\n",
      "1625\n",
      "1650\n",
      "1675\n",
      "1700\n",
      "1725\n",
      "1750\n",
      "1775\n",
      "1800\n",
      "1825\n",
      "1850\n",
      "1875\n",
      "1900\n",
      "1925\n",
      "1950\n",
      "1975\n",
      "2000\n",
      "2025\n",
      "2050\n",
      "2075\n",
      "2100\n",
      "2125\n",
      "2150\n",
      "2175\n",
      "2200\n",
      "2225\n",
      "2250\n",
      "2275\n",
      "2300\n",
      "2325\n",
      "2350\n",
      "2375\n",
      "2400\n",
      "2425\n",
      "2450\n",
      "2475\n",
      "2500\n",
      "2525\n",
      "2550\n",
      "2575\n",
      "2600\n",
      "2625\n",
      "2650\n",
      "2675\n",
      "2700\n",
      "2725\n",
      "2750\n",
      "2775\n",
      "2800\n",
      "2825\n",
      "2850\n",
      "2875\n",
      "2900\n",
      "2925\n",
      "2950\n",
      "2975\n",
      "3000\n",
      "3025\n",
      "3050\n",
      "3075\n",
      "3100\n",
      "3125\n",
      "3150\n",
      "3175\n",
      "3200\n",
      "3225\n",
      "3250\n",
      "3275\n",
      "3300\n",
      "3325\n",
      "3350\n",
      "3375\n",
      "3400\n",
      "3425\n",
      "3450\n",
      "3475\n",
      "3500\n",
      "3525\n",
      "3550\n",
      "3575\n",
      "3600\n",
      "3625\n",
      "3650\n",
      "3675\n",
      "3700\n",
      "3725\n",
      "3750\n",
      "3775\n",
      "3800\n",
      "3825\n",
      "3850\n",
      "3875\n",
      "3900\n",
      "3925\n",
      "3950\n",
      "3975\n",
      "4000\n",
      "4025\n",
      "4050\n",
      "4075\n",
      "4100\n",
      "4125\n",
      "4150\n",
      "4175\n",
      "4200\n",
      "4225\n",
      "4250\n",
      "4275\n",
      "4300\n",
      "4325\n",
      "4350\n",
      "4375\n",
      "4400\n",
      "4425\n",
      "4450\n",
      "4475\n",
      "4500\n",
      "4525\n",
      "4550\n",
      "4575\n",
      "4600\n",
      "4625\n",
      "4650\n",
      "4675\n",
      "4700\n",
      "4725\n",
      "4750\n",
      "4775\n",
      "4800\n",
      "4825\n",
      "4850\n",
      "4875\n",
      "4900\n",
      "4925\n",
      "4950\n",
      "4975\n",
      "5000\n",
      "5025\n",
      "5050\n",
      "5075\n",
      "5100\n",
      "5125\n",
      "5150\n",
      "5175\n",
      "5200\n",
      "5225\n",
      "5250\n",
      "5275\n",
      "5300\n",
      "5325\n",
      "5350\n",
      "5375\n",
      "5400\n",
      "5425\n",
      "5450\n",
      "5475\n",
      "5500\n",
      "5525\n",
      "5550\n",
      "5575\n",
      "5600\n",
      "5625\n",
      "5650\n",
      "5675\n",
      "5700\n",
      "5725\n",
      "5750\n",
      "5775\n",
      "5800\n",
      "5825\n",
      "5850\n",
      "5875\n",
      "5900\n",
      "5925\n",
      "5950\n",
      "5975\n",
      "6000\n",
      "6025\n",
      "6050\n",
      "6075\n",
      "6100\n",
      "6125\n",
      "6150\n",
      "6175\n",
      "6200\n",
      "6225\n",
      "6250\n",
      "6275\n",
      "6300\n",
      "6325\n",
      "6350\n",
      "6375\n",
      "6400\n",
      "6425\n",
      "6450\n",
      "6475\n",
      "6500\n",
      "6525\n",
      "6550\n",
      "6575\n",
      "6600\n",
      "6625\n",
      "6650\n",
      "6675\n",
      "6700\n",
      "6725\n",
      "6750\n",
      "6775\n",
      "6800\n",
      "6825\n",
      "6850\n",
      "6875\n",
      "6900\n",
      "6925\n",
      "6950\n",
      "6975\n",
      "7000\n",
      "7025\n",
      "7050\n",
      "7075\n",
      "7100\n",
      "7125\n",
      "7150\n",
      "7175\n",
      "7200\n",
      "7225\n",
      "7250\n",
      "7275\n",
      "7300\n",
      "7325\n",
      "7350\n",
      "7375\n",
      "7400\n",
      "7425\n",
      "7450\n",
      "7475\n",
      "7500\n",
      "7525\n",
      "7550\n",
      "7575\n",
      "7600\n",
      "7625\n",
      "7650\n",
      "7675\n",
      "7700\n",
      "7725\n",
      "7750\n",
      "7775\n",
      "7800\n",
      "7825\n",
      "7850\n",
      "7875\n",
      "7900\n",
      "7925\n",
      "7950\n",
      "7975\n",
      "8000\n",
      "8025\n",
      "8050\n",
      "8075\n",
      "8100\n",
      "8125\n",
      "8150\n",
      "8175\n",
      "8200\n",
      "8225\n",
      "8250\n",
      "8275\n",
      "8300\n",
      "8325\n",
      "8350\n",
      "8375\n",
      "8400\n",
      "8425\n",
      "8450\n",
      "8475\n",
      "8500\n",
      "8525\n",
      "8550\n",
      "8575\n",
      "8600\n",
      "8625\n",
      "8650\n",
      "8675\n",
      "8700\n",
      "8725\n",
      "8750\n",
      "8775\n",
      "8800\n",
      "8825\n",
      "8850\n",
      "8875\n",
      "8900\n",
      "8925\n",
      "8950\n",
      "8975\n",
      "9000\n",
      "9025\n",
      "9050\n",
      "9075\n",
      "9100\n",
      "9125\n",
      "9150\n",
      "9175\n",
      "9200\n",
      "9225\n",
      "9250\n",
      "9275\n",
      "9300\n",
      "9325\n",
      "9350\n",
      "9375\n",
      "9400\n",
      "9425\n",
      "9450\n",
      "9475\n",
      "9500\n",
      "9525\n",
      "9550\n",
      "9575\n",
      "9600\n",
      "9625\n",
      "9650\n",
      "9675\n",
      "9700\n",
      "9725\n",
      "9750\n",
      "9775\n",
      "9800\n",
      "9825\n",
      "9850\n",
      "9875\n",
      "9900\n",
      "9925\n",
      "9950\n",
      "9975\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# do main stuff here - note there is a main function that repeats this\n",
    "\n",
    "Assessments_Obj = Assessments('data_files_ml_engineer/user_assessment_scores.csv')\n",
    "Interests_Obj = Interests('data_files_ml_engineer/user_interests.csv')\n",
    "Classes_Obj = Classes('data_files_ml_engineer/user_course_views.csv', 'data_files_ml_engineer/course_tags.csv')\n",
    "\n",
    "\n",
    "\n",
    "Obj_List = [Assessments_Obj,Interests_Obj, Classes_Obj]\n",
    "\n",
    "user_lists = [obj.get_user_handles() for obj in Obj_List]\n",
    "\n",
    "\n",
    "\n",
    "user_list = np.unique([item for sublist in user_lists for item in sublist])\n",
    "[obj.set_users(user_list) for obj in Obj_List]\n",
    "\n",
    "print('Loading user data sets')\n",
    "[obj.load_user_data_set() for obj in Obj_List]\n",
    "\n",
    "create_sql_table()\n",
    "print('Calculating Jaccard distances across all axes and storing in sql - {0} entries'.format(len(user_list)))\n",
    "for i in range(1, len(user_list) + 1):\n",
    "    if (i%25) == 0:\n",
    "        print (i)\n",
    "    sql_3_axis_distances_for_one_handle(Assessments_Obj, Interests_Obj, Classes_Obj, i)\n",
    "print('Done. Data stored via sql.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user data sets\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5242596194d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5242596194d6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mObj_List\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading user data sets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_user_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mObj_List\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcreate_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5242596194d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mObj_List\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading user data sets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_user_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mObj_List\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcreate_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9ebabaf03286>\u001b[0m in \u001b[0;36mload_user_data_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0massessment_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_list' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main function.\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    Assessments_Obj = Assessments('data_files_ml_engineer/user_assessment_scores.csv')\n",
    "    Interests_Obj = Interests('data_files_ml_engineer/user_interests.csv')\n",
    "    Classes_Obj = Classes('data_files_ml_engineer/user_course_views.csv', 'data_files_ml_engineer/course_tags.csv')\n",
    "\n",
    "\n",
    "\n",
    "    Obj_List = [Assessments_Obj,Interests_Obj, Classes_Obj]\n",
    "\n",
    "    user_lists = [obj.get_user_handles() for obj in Obj_List]\n",
    "\n",
    "\n",
    "\n",
    "    user_list = np.unique([item for sublist in user_lists for item in sublist])\n",
    "    [obj.set_users(user_list) for obj in Obj_List]\n",
    "    print('Loading user data sets')\n",
    "    [obj.load_user_data_set() for obj in Obj_List]\n",
    "\n",
    "    create_sql_table()\n",
    "    print('Calculating Jaccard distances across all axes and storing in sql - {0} entries'.format(len(user_list)))\n",
    "    for i in range(1, len(user_list) + 1):\n",
    "        if (i%25) == 0:\n",
    "            print (i)\n",
    "        sql_3_axis_distances_for_one_handle(Assessments_Obj, Interests_Obj, Classes_Obj, i)\n",
    "    print('Done. Data stored via sql.')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('dstack.db')\n",
    "  \n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\"SELECT dst_usr, distance FROM distance_matrix where src_usr = 9999 and src_usr != dst_usr ORDER BY distance LIMIT 10\"\"\")\n",
    "        \n",
    "rows = c.fetchall()\n",
    "        \n",
    "        \n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "user_dict =  {k:v for k, v in rows}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1562, 0.0),\n",
       " (5238, 0.0),\n",
       " (6303, 0.0),\n",
       " (4484, 0.5),\n",
       " (4432, 0.5196152422706632),\n",
       " (906, 0.5204164998665332),\n",
       " (2200, 0.5443310539518175),\n",
       " (3605, 0.5446711546122731),\n",
       " (5071, 0.5608545472127794),\n",
       " (453, 0.5773502691896258)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1562: 0.0,\n",
       " 5238: 0.0,\n",
       " 6303: 0.0,\n",
       " 4484: 0.5,\n",
       " 4432: 0.5196152422706632,\n",
       " 906: 0.5204164998665332,\n",
       " 2200: 0.5443310539518175,\n",
       " 3605: 0.5446711546122731,\n",
       " 5071: 0.5608545472127794,\n",
       " 453: 0.5773502691896258}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
